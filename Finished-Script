#!/bin/bash

# Prompt user for VM ID to clone

read -p "Enter the VM ID to clone: " SOURCE_VM_ID

# Generate a random unused VM ID

while true; do
        NEW_VM_ID=$((RANDOM % 10000)) # Adjust range if needed
        if ! qm status "$NEW_VM_ID" > /dev/null 2>&1; then
                break
        fi
done

# Use default name if no name was provided

if [[ -z "$NEW_VM_NAME" ]]; then
        NEW_VM_NAME="cloned-vm-$NEW_VM_ID"
fi 

# Verify NEW_VM_ID
if [[ -z "$NEW_VM_ID" ]]; then
        echo "Error: Failed to generate a vlaid new VM ID."
        exit 1
fi

echo "Generated new VM ID: $NEW_VM_ID"

# Clone the VM with the default name

qm clone "$SOURCE_VM_ID" "$NEW_VM_ID" # --name "$NEW_VM_NAME"
if [ $? -eq 0 ]; then
        echo "Successfully cloned VM."
else
        echo "Failed to clone VM."
        exit 1
fi

# Start the cloned VM

echo "Starting the cloned VM $NEW_VM_ID..."
qm start "$NEW_VM_ID"
if [ $? -ne 0 ]; then
        echo "Failed to start VM $NEW_VM_ID."
        exit 1
fi

echo "Waiting for $NEW_VM_ID..."
# Allow the agent to initialise
sleep 10

# Check qemu-guest-agent is running on the cloned VM"
qm agent "$NEW_VM_ID" ping
if [ $? -eq 0 ]; then
	echo "QEMU guest agent is running"
fi

# Edit VM config file to disconnect interface
echo "Editing $NEW_VM_ID network config to disconnect."
sed -i '9s/.*/net0: virtio=BC:24:11:0A:9E:93,bridge=vmbr0,firewall=1,lock_down=1/' /etc/pve/qemu-server/104.conf

echo "rebooting $NEW_VM_ID for the new config"
qm reboot "$NEW_VM_ID"

echo "Waiting for $NEW_VM_ID to come online..."
sleep 10

echo "Adding network configuration"
qm guest exec "$NEW_VM_ID" -- cp -rf ifcfg-ens18 /etc/sysconfig/network-scripts/ifcfg-ens18

# need to edit the VM config file to reconnect interface
echo "Editing $NEW_VM_ID network config to reconnect."
sed -i '9s/.*/net0: virtio=BC:24:11:0A:9E:93,bridge=vmbr0,firewall=1/' /etc/pve/qemu-server/104.conf

echo "rebooting $NEW_VM_ID for the new config"
qm reboot "$NEW_VM_ID"

echo "Waiting for $NEW_VM_ID to come online..."
sleep 10

# Remove the CD/DVD drive (if attached) from the clone VM

echo "Removed CD/DVD for migration."
qm set "$NEW_VM_ID" -cdrom none
        if [ $? -ne 0 ]; then
        echo "Failed to remove CD/DVD drive."
        exit 1
fi


# Prompt user for target Proxmox node to migrate to

read -p "Enter the target node to migrate the VM to: " TARGET_NODE

# Check if TARGET_NODE is empty

if [[ -z "$TARGET_NODE" ]]; then
        echo "Error: Target node cannot be empty."
        exit 1
fi


# Check if the VM is running, and migrate accordingly

VM_STATUS=$(qm status "$NEW_VM_ID" | awk '{print $2}')
if [[ "$VM_STATUS" == "running" ]]; then
        echo "Migrating VM $NEW_VM_ID to node $TARGET_NODE (Online)..."
        qm migrate "$NEW_VM_ID" "$TARGET_NODE" --online --with-local-disks
else
        echo "Migrating VM $NEW_VM_ID to node $TARGET_NODE (offline)..."
        qm migrate "$NEW_VM_ID" "$TARGET_NODE" 
fi


if [ $? -eq 0 ]; then 
        echo "Successfully migrated VM $NEW_VM_ID to node $TARGET_NODE."
else
        echo "Failed to migrate VM."
        exit 1
fi


# Clones, Names and edits the network interface to turn off. 
# We turn off the NIC to ensure the DHCP does not give the same IP address as the Source-vm and reboot the VM for the command to apply
# Copy the network config file from the source-vm, which will apply the new ip address (?)
# Edit network interface again to turn it back on and reboot to apply commands.
# Then migrates. 

# Would have been easier if we could have changed the ip address on the target node we are migrating too. The reason why we cant is beecause we are executing on node 1
# it can only execute on node 1 and not across nodes. As it only executes locally.
